<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <!-- Favicons -->
    <!-- <link rel="apple-touch-icon" href="./assets/img/kit/free/apple-icon.png"> -->
    <link rel="icon" href="./assets/img/kit/free/yonsei.ico">
    <title>
      Yonsei Vision and Learning Lab.
    </title>
    <!--     Fonts and icons     -->
    <link rel="stylesheet" type="text/css" target="_blank" href="https://fonts.googleapis.com/css?family=Open+Sans:+400,500,600,700|Roboto:300,400,500,700|Roboto+Slab:400,700|Material+Icons" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/latest/css/font-awesome.min.css" />
    <link rel="stylesheet" href="assets/css/material-kit.css?v=2.0.2">
    <!-- Documentation extras -->
    <!-- CSS Just for demo purpose, don't include it in your project -->
    <!-- <link href="./assets/assets-for-demo/demo.css" rel="stylesheet" /> -->
    <!-- iframe removal -->
</head>

<body class="index-page">
    <nav class="navbar navbar-color-on-scroll navbar-transparent navbar-light fixed-top navbar-expand-lg " color-on-scroll="0" id="sectionsNav">
        <div w3-include-html="header.html" class="container"></div>
    </nav>
    
    <div class="page-header2 header-filter clear-filter" data-parallax="true" style="background-image: url('assets/img/yonsei-eagle.jpeg'); background-position-y: -170px; background-position: top;">
        <div class="container">
            <div class="row">
                <div class="col-md-8 ml-auto mr-auto">
                    <div class="brand">
                    </div>
                </div>
            </div>
        </div>
    </div>


    <div class="main main-raised">
        <div class="container">
            <div class="title" style="margin-bottom: -1em;">
                <h3>Publications</h3>
            </div>

<!--             
            <div class="year-pub">
              Preprints
            </div>
 -->

        <div class="year-pub">
          2023
        </div>

        <div class="row-pub all">
          <div class="card" style="width: 97%;">
            <div class="card-body" style="background-color: hsl(0, 0%, 99%);">
              <img class="card-pic-left" src="assets/paper_img/iccv2023-capeam.jpg" width=120px>
              <h4 class="card-title" style="margin-top: -0.1em;">Context-Aware Planning and Environment-Aware Memory for Instruction Following Embodied Agents</h4>
              <p class="card-text">Byeonghwi Kim, Jinyeon Kim, Yuyeong Kim, Cheolhong Min, Jonghyun Choi</p>
              <h6 class="card-subtitle mb-2 text-muted">ICCV 2023<br>(CVPR 2023 Embodied AI Workshop - 1st Place Winner)</h6>

              <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Context-Aware_Planning_and_Environment-Aware_Memory_for_Instruction_Following_Embodied_Agents_ICCV_2023_paper.pdf" target="_blank">PDF </a> &middot;
              <a href="https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_Context-Aware_Planning_and_ICCV_2023_supplemental.zip" target="_blank">Supp </a> &middot;
              <a href="https://bhkim94.github.io/projects/CAPEAM/" target="_new">Project Page </a> &middot;
              <a href="https://askforalfred.com/EAI23/" class="card-link" target="_new">CVPR 2023 Workshop Challenge Page </a> 
            </div>
          </div>            
        </div>

        <div class="row-pub all">
          <div class="card" style="width: 97%;">
            <div class="card-body" style="background-color: rgb(253, 253, 253);">
              <img class="card-pic-left" src="assets/paper_img/iccv2023-cmota.jpg" width=120px>
              <h4 class="card-title" style="margin-top: -0.1em;">Story Visualization by Online Text Augmentation with Context Memory</h4>
              <p class="card-text">Daechul Ahn, Daneul Kim, Gwangmo Song, Seung Hwan Kim, Honglak Lee, Dongyeop Kang, Jonghyun Choi </p>
              <h6 class="card-subtitle mb-2 text-muted">ICCV 2023</h6>

              <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Ahn_Story_Visualization_by_Online_Text_Augmentation_with_Context_Memory_ICCV_2023_paper.pdf" target="_blank">PDF </a> &middot;
              <a href="https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ahn_Story_Visualization_by_ICCV_2023_supplemental.pdf" target="_blank">Supp </a> &middot;
              <a href="https://dcahn12.github.io/projects/CMOTA/" class="card-link" target="_new">Project Page </a> &middot;
              <a href="https://github.com/yonseivnl/cmota" target="_blank">Code </a>        

            </div>
          </div>            
        </div>

        <div class="row-pub all">
          <div class="card" style="width: 97%;">
            <div class="card-body" style="background-color: rgb(253, 253, 253);">
              <img class="card-pic-left" src="assets/paper_img/iccv2023-hiercl.jpg" width=120px>
              <h4 class="card-title" style="margin-top: -0.1em;">Online Continual Learning on Hierarchical Label Expansion</h4>
              <p class="card-text">Byung Hyun Lee, Okchul Jung, Jonghyun Choi, Se Young Chun</p>
              <h6 class="card-subtitle mb-2 text-muted">ICCV 2023</h6>

              <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Online_Continual_Learning_on_Hierarchical_Label_Expansion_ICCV_2023_paper.pdf" target="_blank">PDF </a> &middot;
              <a href="https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Online_Continual_Learning_ICCV_2023_supplemental.pdf" target="_blank">Supp </a> &middot;
              <a href="https://jokc28.github.io/okchul.github.io/" class="card-link" target="_new">Project Page </a> &middot;
              <a href="https://github.com/Hyun1A/HLE" target="_blank">Code </a>        

            </div>
          </div>            
        </div>

        <div class="row-pub all">
          <div class="card" style="width: 97%;">
            <div class="card-body" style="background-color: rgb(253, 253, 253);">
              <img class="card-pic-left" src="assets/paper_img/mobicom2023-miro.jpg" width=120px>
              <h4 class="card-title" style="margin-top: -0.1em;">Cost-effective On-device Continual Learning over Memory Hierarchy with Miro</h4>
              <p class="card-text">Xinyue Ma, Suyeon Jeong, Minjia Zhang, Di Wang, Jonghyun Choi, Myeongjae Jeon</p>
              <h6 class="card-subtitle mb-2 text-muted">M<span style="text-transform: lowercase">obi</span>C<span style="text-transform: lowercase">om</span> 2023</h6>

              <a href="https://arxiv.org/pdf/2308.06053.pdf" target="_blank">PDF (arXiv)</a>, 
              <a href="https://dl.acm.org/doi/10.1145/3570361.3613297" target="_blank">(in ACM)</a>


            </div>
          </div>            
        </div>

        <div class="row-pub all">
          <div class="card" style="width: 97%;">
            <div class="card-body" style="background-color: rgb(253, 253, 253);">
              <img class="card-pic-left" src="assets/paper_img/cvprw2023-mensa.jpg" width=120px>
              <h4 class="card-title" style="margin-top: -0.1em;">MEnsA: Mix-up Ensemble Average for Unsupervised Multi Target Domain Adaptation on 3D Point Clouds</h4>
              <p class="card-text">Ashish Sinha, Jonghyun Choi </p>
              <h6 class="card-subtitle mb-2 text-muted">CVPR 2023 - Workshop on Continual Learning in Computer Vision</h6>

              <a href="https://openaccess.thecvf.com/content/CVPR2023W/L3D-IVU/papers/Sinha_MEnsA_Mix-Up_Ensemble_Average_for_Unsupervised_Multi_Target_Domain_Adaptation_CVPRW_2023_paper.pdf" target="_blank">PDF </a>

            </div>
          </div>            
        </div>
    
        <div class="row-pub all">
          <div class="card" style="width: 97%;">
            <div class="card-body" style="background-color: rgb(253, 253, 253);">
              <img class="card-pic-left" src="assets/paper_img/iclr2023-sdp.jpg" width=120px>
              <h4 class="card-title" style="margin-top: -0.1em;">Online Boundary-Free Continual Learning by Scheduled Data Prior</h4>
              <p class="card-text">Hyunseo Koh, Minhyuk Seo, Jihwan Bang, Hwanjun Song, Deokki Hong, Seulki Park, Jung-Woo Ha, Jonghyun Choi</p>
              <h6 class="card-subtitle mb-2 text-muted">ICLR 2023</h6>

              <a href="https://openreview.net/pdf?id=qco4ekz2Epm" target="_blank">PDF </a> &middot;
              <a href="https://github.com/yonseivnl/sdp" target="_blank">Code </a> 

            </div>
          </div>            
        </div>


          <div class="row-pub all">
            <div class="card" style="width: 97%;">
              <div class="card-body" style="background-color: rgb(253, 253, 253);">
                <img class="card-pic-left" src="assets/paper_img/aaai2023-mocha.jpg" width=120px>
                <h4 class="card-title" style="margin-top: -0.1em;">Multi-level Compositional Reasoning for Interactive Instruction Following</h4>
                <p class="card-text">Suvaansh Bhambri*, Byeonghwi Kim*, Jonghyun Choi</p>
                <h6 class="card-subtitle mb-2 text-muted">AAAI 2023</h6>

                <a href="http://ppolon.github.io/paper/aaai2023-alfred-mocha.pdf" target="_blank">PDF </a> &middot;
                <a href="https://github.com/yonseivnl/mcr-agent" target="_blank">Code </a> 
                
              </div>
            </div>            
          </div>


          <div class="year-pub">
            2022
          </div>

            <div class="row-pub all">
              <div class="card" style="width: 97%;">
                <div class="card-body" style="background-color: rgb(253, 253, 253);">
                  <img class="card-pic-left" src="assets/paper_img/neurips2022-ask4help.jpg" width=120px>
                  <h4 class="card-title" style="margin-top: -0.1em;">Ask4Help: Learning to Leverage an Expert for Embodied Tasks</h4>
                  <p class="card-text">Kunal Pratap Singh, Luca Weihs, Alvaro Herrasti, Jonghyun Choi, Aniruddha Kembhavi, Roozbeh Mottaghi</p>
                  <h6 class="card-subtitle mb-2 text-muted">N<span style="text-transform: lowercase">eur</span>IPS 2022</h6>
                  <a href="https://openreview.net/pdf?id=_bqtjfpj8h" target="_blank">PDF </a> &middot;
                  <a href="https://nips.cc/virtual/2022/poster/54883" target="_blank">Conference page </a>
                </div>
              </div>            
            </div>

            <div class="row-pub all">
              <div class="card" style="width: 97%;">
                <div class="card-body" style="background-color: rgb(253, 253, 253);">
                  <img class="card-pic-left" src="assets/paper_img/bmvc2022-texture.jpg" width=120px>
                  <h4 class="card-title" style="margin-top: -0.1em;">Learning visual representations for transfer learning by suppressing texture</h4>
                  <p class="card-text">Shlok Mishra, Anshul Shah, Ankan Bansal, Janit Anjaria, Jonghyun Choi, Abhinav Shrivastava, Abhishek Sharma, David Jacobs</p>
                  <h6 class="card-subtitle mb-2 text-muted">BMVC 2022</h6>
                  <a href="https://bmvc2022.mpi-inf.mpg.de/0300.pdf" target="_blank">PDF </a> &middot;
                  <a href="https://bmvc2022.mpi-inf.mpg.de/0300_poster.pdf" target="_blank">Poster </a> &middot;
                  <a href="https://bmvc2022.mpi-inf.mpg.de/0300_video.mp4" target="_blank">Video </a>
                </div>
              </div>            
            </div>

            <div class="row-pub all">
              <div class="card" style="width: 97%;">
                <div class="card-body" style="background-color: rgb(253, 253, 253);">
                  <img class="card-pic-left" src="assets/paper_img/arxiv2021_carm.jpg" width=120px>
                  <h4 class="card-title" style="margin-top: -0.1em;">CarM: Hierarchical Episodic Memory for Continual Learning</h4>
                  <p class="card-text">Soobee Lee, Minindu Weerakoon, Jonghyun Choi, Minjia Zhang, Di Wang, Myeongjae Jeon</p>
                  <h6 class="card-subtitle mb-2 text-muted">DAC 2022</h6>
                  <a href="./research/papers/dac2022-carm.pdf" class="card-link" target="_blank">PDF</a> &middot;
                  <a href="https://github.com/supersoob/CarM" target="_blank">Code </a>
                </div>
              </div>            
            </div>

            <div class="row-pub all">
              <div class="card" style="width: 97%;">
                <div class="card-body" style="background-color: rgb(253, 253, 253);">
                  <img class="card-pic-left" src="assets/paper_img/arxiv2021_bssl.jpg" width=120px>
                  <h4 class="card-title" style="margin-top: -0.1em;">Unsupervised Representation Learning for Binary Networks by Joint Classifier Learning</h4>
                  <p class="card-text">Dahyun Kim, Jonghyun Choi</p>
                  <h6 class="card-subtitle mb-2 text-muted">CVPR 2022</h6>
                  <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Unsupervised_Representation_Learning_for_Binary_Networks_by_Joint_Classifier_Learning_CVPR_2022_paper.pdf" target="_blank">PDF</a> &middot;
                  <a href="https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_Unsupervised_Representation_Learning_CVPR_2022_supplemental.pdf" target="_blank">Supp</a> &middot;
                  <a href="https://github.com/naver-ai/burn" target="_blank">Code </a>        
                </div>
              </div>            
            </div>

            <div class="row-pub all">
              <div class="card" style="width: 97%;">
                <div class="card-body" style="background-color: rgb(253, 253, 253);">
                  <img class="card-pic-left" src="assets/paper_img/cvpr2022_noisycl.jpg" width=120px>
                  <h4 class="card-title" style="margin-top: -0.1em;">Online Continual Learning on a Contaminated Data Stream with Blurry Task Boundaries</h4>
                  <p class="card-text">Jihwan Bang, Hyunseo Koh, Seulki Park, Hwanjun Song, Jung-Woo Ha, Jonghyun Choi</p>
                  <h6 class="card-subtitle mb-2 text-muted">CVPR 2022</h6>
                  
                  <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Bang_Online_Continual_Learning_on_a_Contaminated_Data_Stream_With_Blurry_CVPR_2022_paper.pdf" target="_blank">PDF</a> &middot;
                  <a href="https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bang_Online_Continual_Learning_CVPR_2022_supplemental.pdf" target="_blank">Supp</a> &middot;
                  <a href="https://github.com/clovaai/puridiver" target="_blank">Code </a>        
                </div>
              </div>            
            </div>

            <div class="row-pub all">
              <div class="card" style="width: 97%;">
                <div class="card-body" style="background-color: rgb(253, 253, 253);">
                  <img class="card-pic-left" src="assets/paper_img/cvpr2022_eventstereo.jpg" width=120px>
                  <h4 class="card-title" style="margin-top: -0.1em;">Stereo Depth from Events Cameras: Concentrate and Focus on the Future</h4>
                  <p class="card-text">YeongWoo Nam, Mohammad Mostafavi, Kuk-Jin Yoon, Jonghyun Choi</p>
                  <h6 class="card-subtitle mb-2 text-muted">CVPR 2022</h6>

                  <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Nam_Stereo_Depth_From_Events_Cameras_Concentrate_and_Focus_on_the_CVPR_2022_paper.pdf" target="_blank">PDF</a> &middot;
                  <a href="https://openaccess.thecvf.com/content/CVPR2022/supplemental/Nam_Stereo_Depth_From_CVPR_2022_supplemental.pdf" target="_blank">Supp</a> &middot;
                  <a href="https://github.com/yonseivnl/se-cff" target="_blank">Code </a>        
                </div>
              </div>            
            </div>

            <div class="row-pub all">
              <div class="card" style="width: 97%;">
                <div class="card-body" style="background-color: rgb(253, 253, 253);">
                  <img class="card-pic-left" src="assets/paper_img/cvpr2022_structsparse.jpg" width=120px>
                  <h4 class="card-title" style="margin-top: -0.1em;">Attentive Fine-Grained Structured Sparsity for Image Restoration</h4>
                  <p class="card-text">Junghun Oh, Heewon Kim, Seungjun Nah, Cheeun Hong, Jonghyun Choi, Kyoung Mu Lee</p>
                  <h6 class="card-subtitle mb-2 text-muted">CVPR 2022</h6>

                  <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Oh_Attentive_Fine-Grained_Structured_Sparsity_for_Image_Restoration_CVPR_2022_paper.pdf" target="_blank">PDF</a> &middot;
                  <a href="https://openaccess.thecvf.com/content/CVPR2022/supplemental/Oh_Attentive_Fine-Grained_Structured_CVPR_2022_supplemental.pdf" target="_blank">Supp</a> &middot;
                  <a href="https://github.com/JungHunOh/SLS_CVPR2022" target="_blank">Code </a>        

                </div>
              </div>            
            </div>

            <div class="row-pub all">
              <div class="card" style="width: 97%;">
                <div class="card-body" style="background-color: rgb(253, 253, 253);">
                  <img class="card-pic-left" src="../assets/paper_img/cvprw2022_lgmc.jpg" width=120px>
                  <h4 class="card-title">Language Guided Meta-Control for Embodied Instruction Following</h4>
                  <p class="card-text">Divyam Goel, Kunal Pratap Singh, Jonghyun Choi</p>
                  <h6 class="card-subtitle mb-2 text-muted">CVPR 2022 - Workshop on Embodied AI (EAI-2022)</h6>
                  <a href="https://embodied-ai.org/papers/2022/23.pdf" target="_new">PDF</a>
                  <!-- <a href="./papers/cvprw21_poster_bnas_v2.pdf" target="_new">Poster</a> &middot;
                  <a href="./papers/cvprw21_slide_bnas_v2.pdf" target="_new">Talk Slide</a> -->
                </div>
              </div>            
            </div>

            <div class="row-pub all">
              <div class="card" style="width: 97%;">
                <div class="card-body" style="background-color: rgb(253, 253, 253);">
                  <img class="card-pic-left" src="assets/paper_img/arxiv2021_iblurry.jpg" width=120px>
                  <h4 class="card-title" style="margin-top: -0.1em;">Online Continual Learning on Class Incremental Blurry Task Configuration with Anytime Inference</h4>
                  <p class="card-text">Hyunseo Koh, Dahyun Kim, Jung-Woo Ha, Jonghyun Choi</p>
                  <h6 class="card-subtitle mb-2 text-muted">ICLR 2022</h6>
                  <a href="https://arxiv.org/pdf/2110.10031.pdf" class="card-link" target="_blank">PDF</a>
                </div>
              </div>            
            </div>

            
            <!-- Published with Peer Reviews-->
            <div class="year-pub">
              2021
            </div>

            <div class="row-pub all">
              <div class="card" style="width: 97%;">
                <div class="card-body" style="background-color: rgb(253, 253, 253);">
                  <img class="card-pic-left" src="assets/paper_img/emnlp2021_iconary.jpg" width=120px>
                  <h4 class="card-title" style="margin-top: -0.1em;">Iconary: A Pictionary-based Game for Testing Multimodal Communication with Drawings and Text</h4>
                  <p class="card-text">Christopher Clark, Jordi Salvador, Dustin Schwenk, Derrick Bonafilia, Mark Yatskar, Eric Kolve, Alvaro Herrasti, Jonghyun Choi, Sachin Mehta, Sam Skjonsberg, Carissa Schoenick, Aaron Sarnat, Hannaneh Hajishirzi, Aniruddha Kembhavi, Oren Etzioni and Ali Farhadi</p>
                  <h6 class="card-subtitle mb-2 text-muted">EMNLP 2021 - Oral</h6>
                  <a href="./pub.html" class="card-link" target="_blank">Paper coming soon</a>
                </div>
              </div>            
            </div>

            <div class="row-pub all">
              <div class="card" style="width: 97%;">
                <div class="card-body" style="background-color: rgb(253, 253, 253);">
                  <img class="card-pic-left" src="assets/paper_img/iccv2021_zsnlvl.jpg" width=120px>
                  <h4 class="card-title">Zero-Shot Natural Language Video Localization</h4>
                  <p class="card-text">Jinwoo Nam*, Daechul Ahn*, Dongyeop Kang, Seong Jong Ha, Jonghyun Choi</p>
                  <!-- <h6 class="card-subtitle mb-2 text-muted">ICCV 2021 - Oral (Acceptance ratio: 3.2%)</h6> -->
                  <h6 class="card-subtitle mb-2 text-muted">ICCV 2021 - Oral</h6>
                  <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Nam_Zero-Shot_Natural_Language_Video_Localization_ICCV_2021_paper.pdf" class="card-link" target="_new">PDF</a>
                  <a href="https://openaccess.thecvf.com/content/ICCV2021/supplemental/Nam_Zero-Shot_Natural_Language_ICCV_2021_supplemental.zip" class="card-link" target="_new">SuppMat </a>
                </div>
              </div>            
            </div>

            <div class="row-pub all">
              <div class="card" style="width: 97%;">
                <div class="card-body" style="background-color: rgb(253, 253, 253);">
                  <img class="card-pic-left" src="assets/paper_img/arxiv2020_moca.jpg" width=120px>
                  <h4 class="card-title" style="margin-top: -0.1em;">Factorizing Perception and Policy for Interactive Instruction Following</h4>
                  <p class="card-text">Kunal Pratap Singh*, Suvaansh Bhambri*, Byeonghwi Kim*, Roozbeh Mottaghi, Jonghyun Choi</p>
                  <h6 class="card-subtitle mb-2 text-muted" >ICCV 2021<br>(CVPR Embodied AI Workshop 2021 - 2nd Place winner)</h6>
                  <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Singh_Factorizing_Perception_and_Policy_for_Interactive_Instruction_Following_ICCV_2021_paper.pdf" class="card-link" target="_new">PDF</a>
                  <a href="https://openaccess.thecvf.com/content/ICCV2021/supplemental/Singh_Factorizing_Perception_and_ICCV_2021_supplemental.zip" class="card-link" target="_new">SuppMat </a>
                  <a href="https://github.com/gistvision/moca" class="card-link" target="_blank">Code</a>
                  <a href="https://prior.allenai.org/projects/moca" class="card-link" target="_new">Project Page </a>
                  <span class="card-link" style="font-size: small;">(Previous version: <a href="https://arxiv.org/pdf/2012.03208.pdf" class="card-link" target="_blank">MOCA: A Modular Object-Centric Approach for Interactive Instruction Following</a>)</span>
                </div>
              </div>            
            </div>

            <div class="row-pub">
              <div class="card" style="width: 97%;">
                <div class="card-body" style="background-color: rgb(253, 253, 253);">
                  <img class="card-pic-left" src="assets/paper_img/iccv2021_denoising.jpg" width=120px>
                  <h4 class="card-title">Rethinking Deep Image Prior for Denoising</h4>
                  <p class="card-text">Yeonsik Jo, Se Young Chun, Jonghyun Choi</p>
                  <h6 class="card-subtitle mb-2 text-muted">ICCV 2021</h6>
                  <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Jo_Rethinking_Deep_Image_Prior_for_Denoising_ICCV_2021_paper.pdf" class="card-link" target="_new">PDF</a>
                  <a href="https://openaccess.thecvf.com/content/ICCV2021/supplemental/Jo_Rethinking_Deep_Image_ICCV_2021_supplemental.pdf" class="card-link" target="_new">SuppMat </a>
                </div>
              </div>            
            </div>

            <div class="row-pub">
              <div class="card" style="width: 97%;">
                <div class="card-body" style="background-color: rgb(253, 253, 253);">
                  <img class="card-pic-left" src="assets/paper_img/iccv2021_ei_stereo.jpg" width=120px>
                  <h4 class="card-title" style="margin-top: -0.1em;">Event-Intensity Stereo: Estimating Depth by the Best of Both Worlds</h4>
                  <p class="card-text">S. Mohammad Mostafavi I., Kuk-Jin Yoon, Jonghyun Choi</p>
                  <h6 class="card-subtitle mb-2 text-muted">ICCV 2021<br>(CVPR Event Vision Workshop 2021 - 1st Place winner)</h6>
                  <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Mostafavi_Event-Intensity_Stereo_Estimating_Depth_by_the_Best_of_Both_Worlds_ICCV_2021_paper.pdf" class="card-link" target="_new">PDF</a>
                </div>
              </div>            
            </div>

            <div class="row-pub all">
              <div class="card" style="width: 97%;">
                <div class="card-body" style="background-color: rgb(253, 253, 253);">
                  <img class="card-pic-left" src="assets/paper_img/cvpr2020_esr.jpg" width=120px>
                  <h4 class="card-title">E2SRI: Learning to Super Resolve Intensity Images from Events</h4>
                  <p class="card-text">S. Mohammad Mostafavi I., Yeong-woo Nam, Jonghyun Choi, Kuk-Jin Yoon</p>
                  <h6 class="card-subtitle mb-2 text-muted">IEEE Transactions on Pattern Analysis and Machine Intelligence</h6>
                  
                  <a href="https://ieeexplore.ieee.org/document/9485034" class="card-link" target="_blank">PDF</a>
                  <!-- <a href="https://openaccess.thecvf.com/content_CVPR_2020/supplemental/I._Learning_to_Super_CVPR_2020_supplemental.zip" class="card-link" target="_blank">Supp-Mat.</a>
                  <a href="https://github.com/gistvision/e2sri" class="card-link" target="_blank">Code (in prep.)</a>
                  <a href="https://www.youtube.com/watch?v=ZMFAseI1DM8" class="card-link" target="_blank">Video</a>
                  <a href="https://youtu.be/Jl1NeziAHFY?start=1h23m9s&end=1h27m16s" class="card-link" target="_blank">Talk</a> -->
                  <!-- <a href="https://youtu.be/Jl1NeziAHFY?start=4996&end=5236" class="card-link" target="_blank">Talk</a> -->
                </div>
              </div>            
            </div>

            <div class="row-pub">
              <div class="card" style="width: 97%;">
                <div class="card-body" style="background-color: rgb(253, 253, 253);">
                  <img class="card-pic-left" src="assets/paper_img/cvpr2021_rm.jpg" width=120px>
                  <h4 class="card-title">Rainbow Memory: Continual Learning with a Memory of Diverse Samples</h4>
                  <p class="card-text">Jihwan Bang*, Heesu Kim*, Youngjoon Yoo, Jung-Woo Ha, Jonghyun Choi</p>
                  <h6 class="card-subtitle mb-2 text-muted">CVPR 2021</h6>
                  <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Bang_Rainbow_Memory_Continual_Learning_With_a_Memory_of_Diverse_Samples_CVPR_2021_paper.pdf" class="card-link" target="_new">PDF</a>
                  <a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Bang_Rainbow_Memory_Continual_CVPR_2021_supplemental.pdf" class="card-link" target="_new">SuppMat </a>
                  <a href="https://github.com/clovaai/rainbow-memory/" class="card-link" target="_new">Code </a> 
                </div>
              </div>            
            </div>

            <div class="row-pub all">
              <div class="card" style="width: 97%;">
                <div class="card-body" style="background-color: rgb(253, 253, 253);">
                  <img class="card-pic-left" src="assets/paper_img/arxiv2021_bnas_v2.jpg" width=120px>
                  <h4 class="card-title" style="margin-top: -0.1em;">BNAS v2: Learning Architectures for Binary Networks with Empirical Improvements</h4>
                  <p class="card-text">Dahyun Kim, Kunal Pratap Singh, Jonghyun Choi</p>
                  <h6 class="card-subtitle mb-2 text-muted">CVPR 2021 Workshop for Binary Networks for Computer Vision</h6>
                  <a href="https://arxiv.org/pdf/2110.08562.pdf" class="card-link" target="_blank">PDF</a>
                </div>
              </div>            
            </div>

            <div class="row-pub all">
              <div class="card" style="width: 97%;">
                <div class="card-body" style="background-color: rgb(253, 253, 253);">
                  <img class="card-pic-left" src="assets/paper_img/ieee_ed2021.jpg" width=130px>
                  <h4 class="card-title" style="margin-bottom: -0.1em;">Acceleration of Semiconductor Device Simulation With Approximate Solutions Predicted by Trained Neural Networks</h4>
                  <p class="card-text">Seung-Cheol Han, Jonghyun Choi, Sung-Min Hong</p>
                  <h6 class="card-subtitle mb-2 text-muted">IEEE Transactions on Electron Devices 2021</h6>
                  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9426452" class="card-link" target="_blank">PDF</a>
                  <!-- <a href="https://openaccess.thecvf.com/content_CVPR_2020/supplemental/I._Learning_to_Super_CVPR_2020_supplemental.zip" class="card-link" target="_blank">Supp-Mat.</a>
                  <a href="https://github.com/gistvision/e2sri" class="card-link" target="_blank">Code (in prep.)</a>
                  <a href="https://www.youtube.com/watch?v=ZMFAseI1DM8" class="card-link" target="_blank">Video</a> -->
                  <!-- <a href="https://youtu.be/Jl1NeziAHFY?start=1h23m9s&end=1h27m16s" class="card-link" target="_blank">Talk</a> -->
                  <!-- <a href="https://youtu.be/Jl1NeziAHFY?start=4996&end=5236" class="card-link" target="_blank">Talk</a> -->
                </div>
              </div>            
            </div>


            <div class="year-pub">
              2020
            </div>
            <!-- news contents -->

            <div class="row-pub">
              <div class="card" style="width: 97%;">
                <div class="card-body" style="background-color: rgb(253, 253, 253);">
                  <img class="card-pic-left" src="assets/paper_img/eccv2020_bnas.jpg" width=120px>
                  <h4 class="card-title" style="margin-top: -0.1em;">Learning Architectures for Binary Networks</h4>
                  <p class="card-text">Dahyun Kim*, Kunal Pratap Singh*, Jonghyun Choi</p>
                  <h6 class="card-subtitle mb-2 text-muted">ECCV 2020 <br>Samsung Humantech Paper Award 2020 - Bronze</h6>
                  <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123570562.pdf" class="card-link" target="_blank">PDF</a>
                  <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123570562-supp.zip" class="card-link" target="_blank">Supp-Mat</a>
                  <a href="https://github.com/gistvision/bnas/" class="card-link" target="_blank">Code</a>
                </div>
              </div>            
            </div>

            <div class="row-pub all">
              <div class="card" style="width: 97%;">
                <div class="card-body" style="background-color: rgb(253, 253, 253);">
                  <img class="card-pic-left" src="assets/paper_img/cvpr2020_esr.jpg" width=120px>
                  <h4 class="card-title">Learning to Super Resolve Intensity Images from Events</h4>
                  <p class="card-text">S. Mohammad Mostafavi I., Jonghyun Choi, Kuk-Jin Yoon</p>
                  <h6 class="card-subtitle mb-2 text-muted">CVPR 2020 - Oral</h6>
                  <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/I._Learning_to_Super_Resolve_Intensity_Images_From_Events_CVPR_2020_paper.pdf" class="card-link" target="_blank">PDF</a>
                  <a href="https://openaccess.thecvf.com/content_CVPR_2020/supplemental/I._Learning_to_Super_CVPR_2020_supplemental.zip" class="card-link" target="_blank">Supp-Mat.</a>
                  <a href="https://github.com/gistvision/e2sri" class="card-link" target="_blank">Code (in prep.)</a>
                  <a href="https://www.youtube.com/watch?v=ZMFAseI1DM8" class="card-link" target="_blank">Video</a>
                  <!-- <a href="https://youtu.be/Jl1NeziAHFY?start=1h23m9s&end=1h27m16s" class="card-link" target="_blank">Talk</a> -->
                  <!-- <a href="https://youtu.be/Jl1NeziAHFY?start=4996&end=5236" class="card-link" target="_blank">Talk</a> -->
                </div>
              </div>            
            </div>

            <div class="row-pub">
              <div class="card" style="width: 97%;">
                <div class="card-body" style="background-color: rgb(253, 253, 253);">
                  <img class="card-pic-left" src="assets/paper_img/ieee_access2020_incre.jpg" width=120px>
                  <h4 class="card-title">Confidence Calibration for Incremental Learning</h4>
                  <p class="card-text">Dongmin Kang, Yeonsik Jo , Yeongwoo Nam, Jonghyun Choi</p>
                  <h6 class="card-subtitle mb-2 text-muted">IEEE Access</h6>
                  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9133417" class="card-link" target="_blank">PDF</a>
                  <!-- <a href="https://youtu.be/Jl1NeziAHFY?start=1h23m9s&end=1h27m16s" class="card-link" target="_blank">Talk</a> -->
                  <!-- <a href="https://youtu.be/Jl1NeziAHFY?start=4996&end=5236" class="card-link" target="_blank">Talk</a> -->
                </div>
              </div>            
            </div>

            <div class="year-pub">
                2019
            </div>
            <!-- news contents -->

            <div class="row-pub">
                <div class="card" style="width: 97%;">
                  <div class="card-body" style="background-color: rgb(253, 253, 253);">
                    <img class="card-pic-left" src="assets/paper_img/cvpr2019_ehdr.jpg" width=150px>
                    <h4 class="card-title">Event-based High Dynamic Range Image and Very High Frame Rate Video Generation using Conditional Generative Adversarial Networks</h4>
                    <p class="card-text">S. Mohammad Mostafavi I., Lin Wang, Yo-Sung Ho, Kuk-Jin Yoon</p>
                    <h6 class="card-subtitle mb-2 text-muted">CVPR 2019</h6>
                    <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Event-Based_High_Dynamic_Range_Image_and_Very_High_Frame_Rate_CVPR_2019_paper.pdf" class="card-link" target="_blank">PDF</a>
                    <!-- <a href="https://allenai.github.io/one-shot-part-labeling/" class="card-link" target="_blank">Project Page</a> -->
                    <!-- <a href="https://youtu.be/Jl1NeziAHFY?start=1h23m9s&end=1h27m16s" class="card-link" target="_blank">Talk</a> -->
                    <!-- <a href="https://youtu.be/Jl1NeziAHFY?start=4996&end=5236" class="card-link" target="_blank">Talk</a> -->
                  </div>
                </div>            
            </div>


            <div class="year-pub">
                2018
            </div>
            <!-- news contents -->

            <div class="row-pub">
                <div class="card" style="width: 97%;">
                  <div class="card-body" style="background-color: rgb(253, 253, 253);">
                    <img class="card-pic-left" src="assets/paper_img/cvpr2018_ssmn.jpg" width=120px>
                    <h4 class="card-title">Structured Set Matching Networks for One-Shot Part Labeling</h4>
                    <p class="card-text">Jonghyun Choi, Jayant Krishnamurthy, Aniruddha Kembhavi, Ali Farhadi</p>
                    <h6 class="card-subtitle mb-2 text-muted" style="width: 50%;">CVPR 2018 - Spotlight</h6>
                    <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Choi_Structured_Set_Matching_CVPR_2018_paper.pdf" class="card-link" target="_blank">PDF</a>
                    <a href="https://openaccess.thecvf.com/content_cvpr_2018/Supplemental/2732-supp.pdf" class="card-link" target="_blank">SuppMat</a>
                    <a href="https://allenai.github.io/one-shot-part-labeling/" class="card-link" target="_blank">Project Page</a>
                    <!-- <a href="https://youtu.be/Jl1NeziAHFY?start=1h23m9s&end=1h27m16s" class="card-link" target="_blank">Talk</a> -->
                    <a href="https://youtu.be/Jl1NeziAHFY?start=4996&end=5236" class="card-link" target="_blank">Talk</a>
                  </div>
                </div>            
            </div>

            <div class="year-pub">
                2017
            </div>
            <!-- news contents -->

            <div class="row-pub">
                <div class="card" style="width: 97%;">
                  <div class="card-body" style="background-color: rgb(253, 253, 253);">
                    <img class="card-pic-left" src="assets/paper_img/cvpr2017_tqa.jpg" width=150px>
                    <h4 class="card-title">Are You Smarter Than A Sixth Grader? Textbook Question Answering for Multimodal Machine Comprehension</h4>
                    <p class="card-text">Aniruddha  Kembhavi, Minjoon  Seo, Dustin  Schwenk, Jonghyun Choi, Ali Farhadi, Hannaneh  Hajishirzi</p>
                    <h6 class="card-subtitle mb-2 text-muted" style="width: 50%;">CVPR 2017 - Spotlight</h6>
                    <a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Kembhavi_Are_You_Smarter_CVPR_2017_paper.pdf" target="_new">PDF </a> &middot;
                    <a href="https://www.youtube.com/watch?v=gPGeTUmKxrg" target="_new">Talk </a> &middot;
                    <a href="http://textbookqa.org/" target="_new">Dataset Explorer</a>
                  </div>
                </div>            
            </div>

            <div class="year-pub">
                2016
            </div>
            <!-- news contents -->

            <div class="row-pub">
                <div class="card" style="width: 97%;">
                  <div class="card-body" style="background-color: rgb(253, 253, 253);">
                    <img class="card-pic-left" src="assets/paper_img/cvpr2016_anomaly.jpg" width=120px>
                    <h4 class="card-title">Learning Temporal Regularity in Video Sequences</h4>
                    <p class="card-text">Mahmudul Hasan, Jonghyun Choi, Jan Neumann, Amit K. Roy-Chowdhury, Larry S. Davis</p>
                    <h6 class="card-subtitle mb-2 text-muted" style="width: 50%;">CVPR 2016</h6>
                    <a href="http://openaccess.thecvf.com/content_cvpr_2016/papers/Hasan_Learning_Temporal_Regularity_CVPR_2016_paper.pdf" target="_new">PDF </a> &middot;
                    <a href="./paper/cvpr2016_anomaly_supp.pdf" target="_new">Supplementary </a> &middot;
                    <a href="https://github.com/mhasa004/caffe" target="_new">Code </a> &middot;
                    <a href="https://www.youtube.com/watch?v=RQ7dg6wCrQc" target="_new">Video1 </a> &middot;
                    <a href="https://www.youtube.com/watch?v=UXEndaBFq6s" target="_new">Video2 </a> &middot;
                    <a href="./paper/cvpr2016_anomaly_poster.pdf" target="_new">Poster </a>
                  </div>
                </div>            
            </div>            

            <div class="row-pub">
              <div class="card" style="width: 97%;">
                <div class="card-body" style="background-color: rgb(253, 253, 253);">
                  <img class="card-pic-left" src="assets/paper_img/cvpr2016_discpatch.jpg" width=120px>
                  <h4 class="card-title">Mining Discriminative Triplets of Patches for Fine-Grained Classification</h4>
                  <p class="card-text">Yaming Wang, Jonghyun Choi, Vlad I. Morariu, Larry S. Davis</p>
                  <h6 class="card-subtitle mb-2 text-muted" style="width: 50%;">CVPR 2016</h6>
                  <a href="http://openaccess.thecvf.com/content_cvpr_2016/papers/Wang_Mining_Discriminative_Triplets_CVPR_2016_paper.pdf" target="_new">PDF </a> &middot;
                  <a href="./paper/cvpr2016_discpatch_poster.pdf" target="_new">Poster </a>              
                </div>
              </div>            
            </div>            

            <div class="row-pub">
              <div class="card" style="width: 97%;">
                <div class="card-body" style="background-color: rgb(253, 253, 253);">
                  <img class="card-pic-left" src="assets/paper_img/aaai2016_sal.jpg" width=120px>
                  <h4 class="card-title">Knowledge Transfer with Interactive Learning of Semantic Relationships</h4>
                  <p class="card-text">Jonghyun Choi, Sung Ju Hwang, Leonid Sigal, Larry S. Davis</p>
                  <h6 class="card-subtitle mb-2 text-muted" style="width: 50%;">AAAI 2016</h6>
                  <a href="./paper/aaai2016_sal.pdf" target="_new">PDF </a> &middot;
                  <a href="./paper/aaai2016_sal_slide.pdf" target="_new">Slides </a><br>              
                </div>
              </div>            
            </div>            


            <div class="row-pub" style="margin-bottom: 3em;"></div>

        </div>
    </div>
    <!--  End Modal -->
    <div w3-include-html="footer.html"></div>

    <!--   Core JS Files   -->
    <script src="./assets/js/core/jquery.min.js"></script>
    <script src="./assets/js/core/popper.min.js"></script>
    <script src="./assets/js/bootstrap-material-design.js"></script>
    <!--  Plugin for Date Time Picker and Full Calendar Plugin  -->
    <script src="./assets/js/plugins/moment.min.js"></script>
    <!--	Plugin for the Datepicker, full documentation here: https://github.com/Eonasdan/bootstrap-datetimepicker -->
    <script src="./assets/js/plugins/bootstrap-datetimepicker.min.js"></script>
    <!--	Plugin for the Sliders, full documentation here: http://refreshless.com/nouislider/ -->
    <script src="./assets/js/plugins/nouislider.min.js"></script>
    <!-- Material Kit Core initialisations of plugins and Bootstrap Material Design Library -->
    <script src="./assets/js/material-kit.js?v=2.0.2"></script>
    <!-- Fixed Sidebar Nav - js With initialisations For Demo Purpose, Don't Include it in your project -->
    <script src="./assets/assets-for-demo/js/material-kit-demo.js"></script>
    <!-- including html -->
    <script src="./assets/js/include-html.js"></script>    
    <script>
      $(document).ready(function() {

          //init DateTimePickers
          materialKit.initFormExtendedDatetimepickers();

          // // Sliders Init
          // materialKit.initSliders();

          includeHTML();
      });
  </script>    
</body>

</html>