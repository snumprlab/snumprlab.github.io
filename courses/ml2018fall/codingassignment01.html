<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <!-- Favicons -->
    <!-- <link rel="apple-touch-icon" href="./assets/img/kit/free/apple-icon.png"> -->
    <link rel="icon" href="../../assets/img/kit/free/gist.ico">
    <title>
        GIST Computer Vision Lab
    </title>
    <!--     Fonts and icons     -->
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:400,700|Material+Icons" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/latest/css/font-awesome.min.css" />
    <link rel="stylesheet" href="../../assets/css/material-kit.css?v=2.0.2">
    <!-- Documentation extras -->
    <!-- CSS Just for demo purpose, don't include it in your project -->
    <link href="../../assets/assets-for-demo/demo.css" rel="stylesheet" />
    <!-- iframe removal -->
</head>

<body class="index-page">
    <nav class="navbar navbar-color-on-scroll navbar-transparent navbar-light fixed-top navbar-expand-lg " color-on-scroll="0" id="sectionsNav">
        <div class="container">
            <div class="navbar-translate">
                <a class="navbar-brand" href="../../index.html"><b>GIST</b> Computer Vision Lab</a>
                <button class="navbar-toggler" type="button" data-toggle="collapse" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                    <span class="navbar-toggler-icon"></span>
                    <span class="navbar-toggler-icon"></span>
                    <span class="navbar-toggler-icon"></span>
                </button>                
            </div>
            <div class="collapse navbar-collapse">
                <ul class="navbar-nav ml-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="../../people.html">
                            People
                        </a>
                    </li>

                    <li class="nav-item">
                        <a class="nav-link" href="../../pub.html">
                            Publications
                        </a>
                    </li>

                    <li class="nav-item">
                        <a class="nav-link" href="../../courses.html">
                            Courses
                        </a>
                    </li>

                    <li class="nav-item">
                        <a class="nav-link" title="" data-placement="bottom" href="#"> <!-- target="_blank"> -->
                            <i class="fa fa-github"></i>
                        </a>
                    </li>   
                </ul>
            </div>
        </div>
    </nav>
    <div class="page-header2 header-filter clear-filter" data-parallax="true" style="background-image: url('../../assets/img/kit/bg9.png');">
        <div class="container">
            <div class="row">
                <div class="col-md-8 ml-auto mr-auto">
                    <div class="brand">
                    </div>
                </div>
            </div>
        </div>
    </div>


    <div class="main main-raised">
        <div class="container">
            <div class="title">
                <h3 class="title">
                    Coding Assignment 1: Basic classification and decision trees
                </h3>
                <hr>
            </div>

            <h3><a name="intro">Introduction</a></h3>

            We will learn to predict whether students are likely
              to take the Artificial Intelligence course (AI) or the Computer
              Graphics course (CG).  We will begin by writing some very
              simple predictors, just to help familiarize you with
              our environment.  We will then move on to slightly more complex prediction model; the decision
              trees.  We will also look at how these models fare on different
              types of problems.<br><br>

            <b>Note</b>: we will use <strong>Python 2.x</strong> for the project.<br><br>

            The code for this project consists of several Python files, some of
            which you will need to read and understand in order to complete the
            assignment, and some of which you can ignore. <br><br>

            <b>Please start your coding assignment by accepting <a href="https://classroom.github.com/a/bZWn2mEf" target="_new2">a git classroom assignment</a>. It will provide all the codes and supporting files placed in your private repo</b>.

            <hr>
            <table border="0" cellpadding="10">
              <tr><td colspan="2"><b>Files you'll edit:</b></td></tr>
              
              <tr><td><code>dumbClassifiers.py</code></td>
              <td>This contains a handful of "warm up" classifiers to get you
              used to our classification framework.</td></tr>
              
              <tr><td><code>dt.py</code></td>
              <td>Will be your simple implementation of a decision tree classifier.</td></tr>
              

              <tr><td colspan="2"><b>Files you might want to look at:</b></td></tr>
              
              <tr><td><code>binary.py</code></td>
              <td>Our generic interface for binary classifiers (actually works for
              regression and other types of classification, too).</td></tr>

              <tr><td><code>datasets.py</code></td>
              <td>Where a handful of test data sets are stored.</td></tr>

              <tr><td><code>util.py</code></td>
              <td>A handful of useful utility functions: these will undoubtedly
              be helpful to you, so take a look!</td></tr>

              <tr><td><code>runClassifier.py</code></td>
              <td>A few wrappers for doing useful things with classifiers, like
              training them, generating learning curves, etc.</td></tr>

              <tr><td><code>mlGraphics.py</code></td>
              <td>A few useful plotting commands</td></tr>

            </table>
            <hr>

            <b>What to submit:</b> You
              will <a href="https://classroom.github.com/a/bZWn2mEf" target="_new2">handin</a>
              all of the python files listed above under "Files you'll edit".  Finally, you'll hand
              in a <tt>writeup.pdf</tt> file that answers all the written
              questions in this assignment (denoted by "<b>WU#:</b>" in
              this documentation).<br><br>

            <b>Evaluation:</b> Your code will be autograded for
            technical correctness. Please <em>do not</em> change the names of any
            provided functions or classes within the code, or you will wreak havoc
            on the autograder. However, the correctness of your implementation --
            not the autograder's output -- will be the final judge of your score.
            If necessary, we will review and grade assignments individually to
            ensure that you receive due credit for your work.<br><br>

            <b>Academic Dishonesty:</b> We will be checking your code
            against other submissions in the class for logical redundancy. If you
            copy someone else's code and submit it with minor changes, we will
            know. These cheat detectors are quite hard to fool, so please don't
            try. We trust you all to submit your own work only; <em>please</em>
            don't let us down. If you do, we will pursue the strongest
            consequences available to us.<br><br>

            <b>Getting Help:</b> You are not alone!  If you find
            yourself stuck on something, contact the course staff for help.
            Office hours, class time, and Piazza are there for your support;
            please use them.  We want these projects to be rewarding and
            instructional, not frustrating and demoralizing.  But, we don't know
            when or how to help unless you ask.<br><br>

            <b>One more piece of advice:</b> <strong>if you don't know what a variable is, print it out.</strong>

            <hr>
            <h3><a name="warmup">Warming Up to Classifiers</a> <i>(20%)</i></h3>

            Let's begin our foray into classification by looking at some very
            simple classifiers.  There are three classifiers
            in <tt>dumbClassifiers.py</tt>, one is implemented for you, the other
            two you will need to fill in appropriately.<br><br>

            The already implemented one is <tt>AlwaysPredictOne</tt>, a classifier
            that (as its name suggest) always predicts the positive class.  We're
            going to use the <tt>TennisData</tt> dataset from <tt>datasets.py</tt>
            as a running example.  So let's start up python and see how well this
            classifier does on this data.  You should begin by
            importing <tt>util</tt>, <tt>datasets</tt>, <tt>binary</tt>
            and <tt>dumbClassifiers</tt>.  Also, be sure you always have <tt>from
              numpy import *</tt> and <tt>from pylab import *</tt> activated.

            <pre>
            >>> h = dumbClassifiers.AlwaysPredictOne({})
            >>> h
            AlwaysPredictOne
            >>> h.train(datasets.TennisData.X, datasets.TennisData.Y)
            >>> h.predictAll(datasets.TennisData.X)
            array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])
            </pre>

            Indeed, it looks like it's always predicting one!<br><br>

            Now, let's compare these predictions to the truth.  Here's a very
            clever way to compute accuracies (<b>WU1:</b> why is this computation
            equivalent to computing classification accuracy?):

            <pre>
            >>> mean((datasets.TennisData.Y > 0) == (h.predictAll(datasets.TennisData.X) > 0))
            0.6428571428571429
            </pre>

            That's training accuracy; let's check test accuracy:

            <pre>
            >>> mean((datasets.TennisData.Yte > 0) == (h.predictAll(datasets.TennisData.Xte) > 0))
            0.5
            </pre>

            Okay, so it does pretty badly.  That's not surprising, it's really not
            learning anything!!!

            Now, let's use some of the built-in functionality to help do some of
            the grunt work for us.  You'll need to import <tt>runClassifier</tt>.

            <pre>
            >>> runClassifier.trainTestSet(h, datasets.TennisData)
            Training accuracy 0.642857, test accuracy 0.5
            </pre>

            Very convenient!

            Now, your first implementation task will be to implement the missing
            functionality in <tt>AlwaysPredictMostFrequent</tt>.  This actually
            will "learn" something simple.  Upon receiving training data, it will
            simply remember whether +1 is more common or -1 is more common.  It
            will then always predict this label for future data.  Once you've
            implemented this, you can test it:

            <pre>
            >>> h = dumbClassifiers.AlwaysPredictMostFrequent({})
            >>> runClassifier.trainTestSet(h, datasets.TennisData)
            Training accuracy 0.642857, test accuracy 0.5
            >>> h
            AlwaysPredictMostFrequent(1)
            </pre>

            Okay, so it does the same as <tt>AlwaysPredictOne</tt>, but that's
            because +1 is more common in that training data.  We can see a
            difference if we change to a different dataset: <tt>CFTookAI</tt> is a
            classification problem where we try to predict whether a student has
            taken AI based on the other classes they've taken.

            <pre>
            >>> runClassifier.trainTestSet(dumbClassifiers.AlwaysPredictOne({}), datasets.CFTookAI)
            Training accuracy 0.515, test accuracy 0.42
            >>> runClassifier.trainTestSet(dumbClassifiers.AlwaysPredictMostFrequent({}), datasets.CFTookAI)
            Training accuracy 0.515, test accuracy 0.42
            </pre>

            Since the majority class is "1", these do the same here.

            The last dumb classifier we'll implement
            is <tt>FirstFeatureClassifier</tt>.  This actually does something
            slightly non-trivial.  It looks at the first feature
            (i.e., <tt>X[0]</tt>) and uses this to make a prediction.  Based on
            the training data, it figures out what is the most common class for
            the case when <tt>X[0] > 0</tt> and the most common class for the case
            when <tt>X[0] <= 0</tt>.  Upon receiving a test point, it checks the
            value of <tt>X[0]</tt> and returns the corresponding class.  Once
            you've implemented this, you can check it's performance:

            <pre>
            >>> runClassifier.trainTestSet(dumbClassifiers.FirstFeatureClassifier({}), datasets.TennisData)
            Training accuracy 0.714286, test accuracy 0.666667
            >>> runClassifier.trainTestSet(dumbClassifiers.FirstFeatureClassifier({}), datasets.CFTookAI)
            Training accuracy 0.515, test accuracy 0.42
            >>> runClassifier.trainTestSet(dumbClassifiers.FirstFeatureClassifier({}), datasets.CFTookCG)
            Training accuracy 0.545, test accuracy 0.49
            </pre>

            (Here, <tt>CFTookCG</tt> is like <tt>CFTookAI</tt> but for computer
            graphics rather than artificial intelligence.)

            As we can see, this does better again on TennisData, but doesn't
            really help on AI.

            <hr>
            <h3><a name="dt">Decision Trees</a> <i>(80%)</i></h3>

            Our next task is to implement a decision tree classifier.  There is
            stub code in <tt>dt.py</tt> that you should edit.  Decision trees are
            stored as simple data structures.  Each node in the tree has
            a <tt>.isLeaf</tt> boolean that tells us if this node is a leaf (as
            opposed to an internal node).  Leaf nodes have a <tt>.label</tt> field
            that says what class to return at this leaf.  Internal nodes have:
            a <tt>.feature</tt> value that tells us what feature to split on;
            a <tt>.left</tt> <i>tree</i> that tells us what to do when the feature
            value is <i>less than 0.5</i>; and a <tt>.right</tt> <i>tree</i> that
            tells us what to do when the feature value is <i>at least 0.5</i>.
            To get a sense of how the data structure works, look at
            the <tt>displayTree</tt> function that prints out a tree.

            Your first task is to implement the training procedure for decision
            trees.  We've provided a fair amount of the code, which should help
            you guard against corner cases.  (Hint: take a look
            at <tt>util.py</tt> for some useful functions for implementing
            training.  Once you've implemented the training function, we can test
            it on simple data:

            <pre>
            >>> h = dt.DT({'maxDepth': 1})
            >>> h
            Leaf 1

            >>> h.train(datasets.TennisData.X, datasets.TennisData.Y)
            >>> h
            Branch 6
              Leaf 1.0
              Leaf -1.0
            </pre>

            This is for a simple depth-one decision tree (aka a decision stump).
            If we let it get deeper, we get things like:

            <pre>
            >>> h = dt.DT({'maxDepth': 2})
            >>> h.train(datasets.TennisData.X, datasets.TennisData.Y)
            >>> h
            Branch 6
              Branch 7
                Leaf 1.0
                Leaf 1.0
              Branch 1
                Leaf -1.0
                Leaf 1.0

            >>> h = dt.DT({'maxDepth': 5})
            >>> h.train(datasets.TennisData.X, datasets.TennisData.Y)
            >>> h
            Branch 6
              Branch 7
                Leaf 1.0
                Branch 2
                  Leaf 1.0
                  Leaf -1.0
              Branch 1
                Branch 7
                  Branch 2
                    Leaf -1.0
                    Leaf 1.0
                  Leaf -1.0
                Leaf 1.0
            </pre>

            Now, you should go implement prediction.  This should be easier than
            training!  We can test by:

            <pre>
            >>> runClassifier.trainTestSet(dt.DT({'maxDepth': 1}), datasets.TennisData)
            Training accuracy 0.714286, test accuracy 1
            >>> runClassifier.trainTestSet(dt.DT({'maxDepth': 2}), datasets.TennisData)
            Training accuracy 0.857143, test accuracy 1
            >>> runClassifier.trainTestSet(dt.DT({'maxDepth': 3}), datasets.TennisData)
            Training accuracy 0.928571, test accuracy 1
            >>> runClassifier.trainTestSet(dt.DT({'maxDepth': 5}), datasets.TennisData)
            Training accuracy 1, test accuracy 1
            </pre>

            Now, let's see how well this does on our (computer graphics) recommender data:

            <pre>
            >>> runClassifier.trainTestSet(dt.DT({'maxDepth': 1}), datasets.CFTookCG)
            Training accuracy 0.56, test accuracy 0.48
            >>> runClassifier.trainTestSet(dt.DT({'maxDepth': 3}), datasets.CFTookCG)
            Training accuracy 0.6325, test accuracy 0.5
            >>> runClassifier.trainTestSet(dt.DT({'maxDepth': 5}), datasets.CFTookCG)
            Training accuracy 0.7475, test accuracy 0.6
            </pre>

            Looks like it does better than the dumb classifiers on training data,
            as well as on test data!  Hopefully we can do even better in the
            future!

            We can use more <tt>runClassifier</tt> functions to generate learning
            curves and hyperparameter curves:

            <pre>
            >>> curve = runClassifier.learningCurveSet(dt.DT({'maxDepth': 5}), datasets.CFTookAI)
            [snip]
            >>> runClassifier.plotCurve('DT on AI', curve)
            </pre>

            This plots training and test accuracy as a function of the number of
            data points (x-axis) used for training.

            <b>WU2:</b> We should see training accuracy (roughly) going down and
            test accuracy (roughly) going up.  Why does training accuracy tend to
            go <i>down?</i>  Why is test accuracy not monotonically
            increasing?

            We can also generate similar curves by changing the maximum depth
            hyperparameter:

            <pre>
            >>> curve = runClassifier.hyperparamCurveSet(dt.DT({'maxDepth': 5}), 'maxDepth', [1,2,3,4,5,6,7,8,9,10], datasets.CFTookAI)
            [snip]
            >>> runClassifier.plotCurve('DT on AI (hyperparameter)', curve)
            </pre>

            Now, the x-axis is the value of the maximum depth.

            <b>WU3:</b> You should see training accuracy monotonically increasing
            and test accuracy making a (wavy) hill.  Which of these
            is <i>guaranteed</i> to happen and which is just something we might
            expect to happen?  Why?

            <b>WU4:</b> Train a decision tree on the CG data with a maximum depth
            of 3.  If you look in <tt>datasets.CFTookCG.courseIds</tt>
            and <tt>.courseNames</tt> you'll find the corresponding course for
            each feature.  The first feature is a constant-one "bias" feature.
            Draw out the decision tree for this classifier, but put in the actual
            course names/ids as the features.  Interpret this tree: do these
            courses seem like they are actually indicative of whether someone
            might take CG?

        </div>
    </div>

    <!--  End Modal -->
    <footer class="footer ">
        <div class="container">
            <nav class="pull-left">
                <ul>
                    <li class="text-left">
                        <div class="special">
                            GIST Computer Vision Lab
                        </div>
                        <div class="special-light">
                            Dasan Building<br/>
                            GIST, Gwangju, South Korea
                        </div>
                    </li>
                </ul>
            </nav>
            <div class="copyright pull-right special">
                Original Template from &copy;
                <script>
                    document.write(new Date().getFullYear())
                </script>, made with <i class="material-icons">favorite</i> by
                <a href="https://www.creative-tim.com" target="_blank">Creative Tim</a> for a better web.
                Modified by Jonghyun Choi
            </div>
        </div>
    </footer>
    <!--   Core JS Files   -->
    <script src="../../assets/js/core/jquery.min.js"></script>
    <script src="../../assets/js/core/popper.min.js"></script>
    <script src="../../assets/js/bootstrap-material-design.js"></script>
    <!--  Plugin for Date Time Picker and Full Calendar Plugin  -->
    <script src="../../assets/js/plugins/moment.min.js"></script>
    <!--	Plugin for the Datepicker, full documentation here: https://github.com/Eonasdan/bootstrap-datetimepicker -->
    <script src="../../assets/js/plugins/bootstrap-datetimepicker.min.js"></script>
    <!--	Plugin for the Sliders, full documentation here: http://refreshless.com/nouislider/ -->
    <script src="../../assets/js/plugins/nouislider.min.js"></script>
    <!-- Material Kit Core initialisations of plugins and Bootstrap Material Design Library -->
    <script src="../../assets/js/material-kit.js?v=2.0.2"></script>
    <!-- Fixed Sidebar Nav - js With initialisations For Demo Purpose, Don't Include it in your project -->
    <script src="../../assets/assets-for-demo/js/material-kit-demo.js"></script>
    <script>
        $(document).ready(function() {

            //init DateTimePickers
            materialKit.initFormExtendedDatetimepickers();

            // Sliders Init
            //materialKit.initSliders();
        });
    </script>
</body>

</html>
